{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds_opt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIYHYzGzwJD3"
      },
      "source": [
        "I have used the same model in this file also, just with a few optimization techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SuW-ROIixKu"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB-cHyebkmkT"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_no6mRpckokA"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIKEA0mTkqo_"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68GHcCSwkty4"
      },
      "source": [
        "! kaggle datasets download -d gpiosenka/100-bird-species/birds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSib1Okhkx50"
      },
      "source": [
        "! mkdir train\n",
        "! unzip 100-bird-species.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWALnVck1d_"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ20jLkFk6Va"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "traindata = datasets.ImageFolder('train/birds/train', transform=transform)\n",
        "trainloader=torch.utils.data.DataLoader(traindata,batch_size=64,shuffle=True)\n",
        "testdata = datasets.ImageFolder('train/birds/test', transform=transform)\n",
        "testloader=torch.utils.data.DataLoader(traindata,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRRrfRBxk-AW"
      },
      "source": [
        "gpu=torch.cuda.is_available()\n",
        "gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYvcpuh5lBSX"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv0=nn.Conv2d(3,64,7,2,3)\n",
        "    self.bn0=nn.BatchNorm2d(64)\n",
        "    self.conv11=nn.Conv2d(64,64,3,padding=1)\n",
        "    self.bn11=nn.BatchNorm2d(64)\n",
        "    self.conv12=nn.Conv2d(64,64,3,padding=1)\n",
        "    self.short1=nn.Identity()\n",
        "    self.bn12=nn.BatchNorm2d(64)\n",
        "    self.conv21=nn.Conv2d(64,128,3,2,1)\n",
        "    self.bn21=nn.BatchNorm2d(128)\n",
        "    self.conv22=nn.Conv2d(128,128,3,padding=1)\n",
        "    self.short2=nn.Conv2d(64,128,1,2)\n",
        "    self.bn22=nn.BatchNorm2d(128)\n",
        "    self.conv31=nn.Conv2d(128,256,3,2,1)\n",
        "    self.bn31=nn.BatchNorm2d(256)\n",
        "    self.conv32=nn.Conv2d(256,256,3,padding=1)\n",
        "    self.short3=nn.Conv2d(128,256,1,2)\n",
        "    self.bn32=nn.BatchNorm2d(256)\n",
        "    self.conv41=nn.Conv2d(256,512,3,2,1)\n",
        "    self.bn41=nn.BatchNorm2d(512)\n",
        "    self.conv42=nn.Conv2d(512,512,3,padding=1)\n",
        "    self.short4=nn.Conv2d(256,512,1,2)\n",
        "    self.bn42=nn.BatchNorm2d(512)\n",
        "    self.mpool=nn.MaxPool2d(3,2)\n",
        "    self.pool=nn.AvgPool2d(7)\n",
        "    self.fc=nn.Linear(512,275)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.bn0(self.conv0(x)))\n",
        "#size=112\n",
        "    x=self.mpool(x)\n",
        "#size=56\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn11(self.conv11(x)))\n",
        "      x=self.bn12(self.conv12(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=56\n",
        "    idx=self.short2(x)\n",
        "    x=F.relu(self.bn21(self.conv21(x)))    \n",
        "    x=self.bn22(self.conv22(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn22(self.conv22(x)))\n",
        "      x=self.bn22(self.conv22(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=28\n",
        "    idx=self.short3(x)\n",
        "    x=F.relu(self.bn31(self.conv31(x)))\n",
        "    x=self.bn32(self.conv32(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn32(self.conv32(x)))\n",
        "      x=self.bn32(self.conv32(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=14\n",
        "    idx=self.short4(x)\n",
        "    x=F.relu(self.bn41(self.conv41(x)))\n",
        "    x=self.bn42(self.conv42(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn42(self.conv42(x)))\n",
        "      x=self.bn42(self.conv42(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=7\n",
        "    x=self.pool(x)\n",
        "#size=1\n",
        "    x=torch.flatten(x,1)\n",
        "#size=512\n",
        "    #print(x.shape)\n",
        "    x=self.fc(x)\n",
        "    x=F.log_softmax(x,dim=1)\n",
        "    #print(x[0:4,0:4])\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypO5dpSwVXG"
      },
      "source": [
        "I have introduced momentum , weight-decay(L2 regularization) and scheduler. The weight decay and momentum hyper parameters have been kept same as in the original paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ1ZXD30Av9D",
        "outputId": "58e30d09-15ad-4a47-8eb9-3793fc4d0673"
      },
      "source": [
        "model=Net()\n",
        "print(model)\n",
        "if gpu:\n",
        "  model.cuda()\n",
        "from torch import optim as optim\n",
        "criterion=nn.NLLLoss()\n",
        "#optimizer=optim.SGD(model.parameters(),lr=0.1)\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.1,weight_decay=0.0001,momentum=0.9)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau as rlr \n",
        "schedular=rlr(optimizer,patience=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short1): Identity()\n",
            "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv21): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short2): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv31): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv41): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (mpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  (fc): Linear(in_features=512, out_features=275, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voRDRYIiwgKt"
      },
      "source": [
        "I have initialized the weights and tried to mimic the He initialization as used in the original paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79RnvKh9pZ_4"
      },
      "source": [
        "def init_all(model):\n",
        "  for p in model.parameters():\n",
        "    if (len(p.shape)==2 or len(p.shape)==3 or len(p.shape)==4):\n",
        "      nn.init.kaiming_normal_(p,nonlinearity='relu')\n",
        "init_all(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx_x114aM2g1",
        "outputId": "385ac227-b061-4957-9076-80608da3015c"
      },
      "source": [
        "epochs=8\n",
        "ploss=float('inf')\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  i=0\n",
        "  for images,classes in trainloader:\n",
        "    i=i+1\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i==600:\n",
        "      break\n",
        "  ttloss=0\n",
        "  model.eval()\n",
        "  for images,classes in testloader:\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    ttloss+=loss.item()\n",
        "  ttloss=ttloss/len(testloader)\n",
        "  schedular.step(ttloss)\n",
        "  print(\"Test loss epoch\",e+1,\":\",ttloss)\n",
        "  if ttloss<ploss:\n",
        "    ploss=ttloss\n",
        "    torch.save(model.state_dict(), 'resnet04.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss epoch 1 : 5.308291706171903\n",
            "Test loss epoch 2 : 5.065412880538346\n",
            "Test loss epoch 3 : 3.2730865966189993\n",
            "Test loss epoch 4 : 2.870991131121462\n",
            "Test loss epoch 5 : 2.235003604323833\n",
            "Test loss epoch 6 : 3.3458738947746816\n",
            "Test loss epoch 7 : 3.166197335371723\n",
            "Test loss epoch 8 : 1.7527410535069254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iHi8QNPsZmx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeUhqZYxsahX"
      },
      "source": [
        "model_save_name = 'resnet04.pt'\n",
        "path = F\"/content/gdrive/MyDrive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9s1f2ROR0_a",
        "outputId": "d1670b30-4fd7-4de2-9ba2-aa4e5085c7e7"
      },
      "source": [
        "epochs=4\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  i=0\n",
        "  for images,classes in trainloader:\n",
        "    i=i+1\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i==600:\n",
        "      break\n",
        "  ttloss=0\n",
        "  model.eval()\n",
        "  for images,classes in testloader:\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    ttloss+=loss.item()\n",
        "  ttloss=ttloss/len(testloader)\n",
        "  schedular.step(ttloss)\n",
        "  print(\"Test loss epoch\",e+9,\":\",ttloss)\n",
        "  if ttloss<ploss:\n",
        "    ploss=ttloss\n",
        "    torch.save(model.state_dict(), 'resnet04.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss epoch 9 : 2.3814081431596312\n",
            "Test loss epoch 10 : 3.2846823400491245\n",
            "Test loss epoch 11 : 3.278533561663194\n",
            "Test loss epoch 12 : 2.2252861421990704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhhBDmFnXjS7",
        "outputId": "f9905a09-118d-41c5-8cbb-260f5fd31923"
      },
      "source": [
        "epochs=4\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  i=0\n",
        "  for images,classes in trainloader:\n",
        "    i=i+1\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i==600:\n",
        "      break\n",
        "  ttloss=0\n",
        "  model.eval()\n",
        "  for images,classes in testloader:\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    ttloss+=loss.item()\n",
        "  ttloss=ttloss/len(testloader)\n",
        "  schedular.step(ttloss)\n",
        "  print(\"Test loss epoch\",e+13,\":\",ttloss)\n",
        "  if ttloss<ploss:\n",
        "    ploss=ttloss\n",
        "    torch.save(model.state_dict(), 'resnet04.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss epoch 13 : 2.2045498887052783\n",
            "Test loss epoch 14 : 2.31932096918682\n",
            "Test loss epoch 15 : 2.1965887140144003\n",
            "Test loss epoch 16 : 2.2589126918223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_v-qgAtw8O0"
      },
      "source": [
        "The minimum test loss I got was 1.75(epoch 8) which would given an accuracy of about 60%. "
      ]
    }
  ]
}