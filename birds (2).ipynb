{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62rEDSaftuQX"
      },
      "source": [
        "After trying a lot of different things, I have put two models in two different files, this one without optimization techniques and the second one with optimization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VJgW15YuHPG"
      },
      "source": [
        "I initially used the original Resnet model but then reduced the number of layers. Also, the model was not learning at all so I have to use Batch Normalization in both the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SuW-ROIixKu"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB-cHyebkmkT"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_no6mRpckokA"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIKEA0mTkqo_"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68GHcCSwkty4"
      },
      "source": [
        "! kaggle datasets download -d gpiosenka/100-bird-species/birds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSib1Okhkx50"
      },
      "source": [
        "! mkdir train\n",
        "! unzip 100-bird-species.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWALnVck1d_"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er6JnPQUvQpg"
      },
      "source": [
        "I used batch-size of 64 while it was originally 256 in Resnet paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ20jLkFk6Va"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "traindata = datasets.ImageFolder('train/birds/train', transform=transform)\n",
        "trainloader=torch.utils.data.DataLoader(traindata,batch_size=64,shuffle=True)\n",
        "testdata = datasets.ImageFolder('train/birds/test', transform=transform)\n",
        "testloader=torch.utils.data.DataLoader(traindata,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRRrfRBxk-AW"
      },
      "source": [
        "gpu=torch.cuda.is_available()\n",
        "gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYvcpuh5lBSX"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv0=nn.Conv2d(3,64,7,2,3)\n",
        "    self.bn0=nn.BatchNorm2d(64)\n",
        "    self.conv11=nn.Conv2d(64,64,3,padding=1)\n",
        "    self.bn11=nn.BatchNorm2d(64)\n",
        "    self.conv12=nn.Conv2d(64,64,3,padding=1)\n",
        "    self.short1=nn.Identity()\n",
        "    self.bn12=nn.BatchNorm2d(64)\n",
        "    self.conv21=nn.Conv2d(64,128,3,2,1)\n",
        "    self.bn21=nn.BatchNorm2d(128)\n",
        "    self.conv22=nn.Conv2d(128,128,3,padding=1)\n",
        "    self.short2=nn.Conv2d(64,128,1,2)\n",
        "    self.bn22=nn.BatchNorm2d(128)\n",
        "    self.conv31=nn.Conv2d(128,256,3,2,1)\n",
        "    self.bn31=nn.BatchNorm2d(256)\n",
        "    self.conv32=nn.Conv2d(256,256,3,padding=1)\n",
        "    self.short3=nn.Conv2d(128,256,1,2)\n",
        "    self.bn32=nn.BatchNorm2d(256)\n",
        "    self.conv41=nn.Conv2d(256,512,3,2,1)\n",
        "    self.bn41=nn.BatchNorm2d(512)\n",
        "    self.conv42=nn.Conv2d(512,512,3,padding=1)\n",
        "    self.short4=nn.Conv2d(256,512,1,2)\n",
        "    self.bn42=nn.BatchNorm2d(512)\n",
        "    self.mpool=nn.MaxPool2d(3,2)\n",
        "    self.pool=nn.AvgPool2d(7)\n",
        "    self.fc=nn.Linear(512,275)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.bn0(self.conv0(x)))\n",
        "#size=112\n",
        "    x=self.mpool(x)\n",
        "#size=56\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn11(self.conv11(x)))\n",
        "      x=self.bn12(self.conv12(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=56\n",
        "    idx=self.short2(x)\n",
        "    x=F.relu(self.bn21(self.conv21(x)))    \n",
        "    x=self.bn22(self.conv22(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn22(self.conv22(x)))\n",
        "      x=self.bn22(self.conv22(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=28\n",
        "    idx=self.short3(x)\n",
        "    x=F.relu(self.bn31(self.conv31(x)))\n",
        "    x=self.bn32(self.conv32(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn32(self.conv32(x)))\n",
        "      x=self.bn32(self.conv32(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=14\n",
        "    idx=self.short4(x)\n",
        "    x=F.relu(self.bn41(self.conv41(x)))\n",
        "    x=self.bn42(self.conv42(x))\n",
        "    x=F.relu(x+idx)\n",
        "    for i in range(1):\n",
        "      idx=self.short1(x)\n",
        "      x=F.relu(self.bn42(self.conv42(x)))\n",
        "      x=self.bn42(self.conv42(x))\n",
        "      x=F.relu(x+idx)\n",
        "#size=7\n",
        "    x=self.pool(x)\n",
        "#size=1\n",
        "    x=torch.flatten(x,1)\n",
        "#size=512\n",
        "    #print(x.shape)\n",
        "    x=self.fc(x)\n",
        "    x=F.log_softmax(x,dim=1)\n",
        "    #print(x[0:4,0:4])\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIWPvoll9M4w",
        "outputId": "de3a038d-86b0-4e34-c6db-a797502a9d82"
      },
      "source": [
        "model=Net()\n",
        "print(model)\n",
        "if gpu:\n",
        "  model.cuda()\n",
        "from torch import optim as optim\n",
        "criterion=nn.NLLLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short1): Identity()\n",
            "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv21): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short2): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv31): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv41): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (bn41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (short4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (mpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  (fc): Linear(in_features=512, out_features=275, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yA9FCcEERS0",
        "outputId": "4d8c9b28-7dbe-4778-97f5-3e5e1c956507"
      },
      "source": [
        "epochs=8\n",
        "ploss=float('inf')\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  i=0\n",
        "  for images,classes in trainloader:\n",
        "    i=i+1\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i==600:\n",
        "      break\n",
        "  ttloss=0\n",
        "  model.eval()\n",
        "  for images,classes in testloader:\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    ttloss+=loss.item()\n",
        "  ttloss=ttloss/len(testloader)\n",
        "  print(\"Test loss epoch\",e+1,\":\",ttloss)\n",
        "  if ttloss<ploss:\n",
        "    ploss=ttloss\n",
        "    torch.save(model.state_dict(), 'resnet03.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss epoch 1 : 4.45321835945179\n",
            "Test loss epoch 2 : 4.06216389173037\n",
            "Test loss epoch 3 : 3.6756689087911085\n",
            "Test loss epoch 4 : 3.86742931681794\n",
            "Test loss epoch 5 : 3.545668075611065\n",
            "Test loss epoch 6 : 3.342251757135639\n",
            "Test loss epoch 7 : 3.444317351688038\n",
            "Test loss epoch 8 : 3.310756290500814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmYAw4VTsJgq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiSRODntsC1Z"
      },
      "source": [
        "model_save_name = 'resnet03.pt'\n",
        "path = F\"/content/gdrive/MyDrive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSt7hHp4rkp-"
      },
      "source": [
        "optimizer=optim.SGD(model.parameters(),lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDXdcuvKObG5",
        "outputId": "d11be763-05cf-477c-a3b6-1dea3b236eac"
      },
      "source": [
        "epochs=4\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  i=0\n",
        "  for images,classes in trainloader:\n",
        "    i=i+1\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i==600:\n",
        "      break\n",
        "  ttloss=0\n",
        "  model.eval()\n",
        "  for images,classes in testloader:\n",
        "    if gpu:\n",
        "      images,classes=images.cuda(),classes.cuda()\n",
        "    output=model(images)\n",
        "    loss=criterion(output,classes)\n",
        "    ttloss+=loss.item()\n",
        "  ttloss=ttloss/len(testloader)\n",
        "  print(\"Test loss epoch\",e+9,\":\",ttloss)\n",
        "  if ttloss<ploss:\n",
        "    ploss=ttloss\n",
        "    torch.save(model.state_dict(), 'resnet03.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss epoch 9 : 3.4217023950118524\n",
            "Test loss epoch 10 : 3.2041431735088297\n",
            "Test loss epoch 11 : 3.055013313695982\n",
            "Test loss epoch 12 : 3.2094886302948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wc3a_a5vo7G"
      },
      "source": [
        "model_save_name = 'resnet03.pt'\n",
        "path = F\"/content/gdrive/MyDrive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm8ARoqsvVkR"
      },
      "source": [
        "Till the 12 epochs, Ithe minimum training loss was 3.05 (epoch 11) which would have given accuracy of about 50%.\n",
        "\n"
      ]
    }
  ]
}