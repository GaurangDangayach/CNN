{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90e2453a7f6c44eb8dfe304c649d3659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46dbabb0bdba48b980bdf6a8ddc7d761",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a62a4b467504fb0838d5419c830d1f6",
              "IPY_MODEL_e836f0c9edfb4472956c6c6e62b65f82"
            ]
          }
        },
        "46dbabb0bdba48b980bdf6a8ddc7d761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a62a4b467504fb0838d5419c830d1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_696826c5aa2840b898453b476cae8d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bcc718493f1482c852c02e1aca74728"
          }
        },
        "e836f0c9edfb4472956c6c6e62b65f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46dafd59009f49d8b6c1bf8c213c0b1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [01:58&lt;00:00, 1444065.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_979187931f8448bf95e192ee86d32449"
          }
        },
        "696826c5aa2840b898453b476cae8d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bcc718493f1482c852c02e1aca74728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46dafd59009f49d8b6c1bf8c213c0b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "979187931f8448bf95e192ee86d32449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4VTpWf2iGj6"
      },
      "source": [
        "# VGG19 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "914jZIiuiRXX"
      },
      "source": [
        "I have tried to implement VGG19 architecture on the CIFAR-10 dataset. I resized the images to 224*224 to match the Imagenet dataset. The architecture is kept same and some hyperparameters are also kept same. The batch size used is 20 instead of original 256."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g-1uRoKFKN0"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyL47Pi9cLGE",
        "outputId": "b519a021-2b32-43dc-9e66-9833292122e2"
      },
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3wZmIqcg9p"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "90e2453a7f6c44eb8dfe304c649d3659",
            "46dbabb0bdba48b980bdf6a8ddc7d761",
            "2a62a4b467504fb0838d5419c830d1f6",
            "e836f0c9edfb4472956c6c6e62b65f82",
            "696826c5aa2840b898453b476cae8d61",
            "8bcc718493f1482c852c02e1aca74728",
            "46dafd59009f49d8b6c1bf8c213c0b1d",
            "979187931f8448bf95e192ee86d32449"
          ]
        },
        "id": "Q3uaFD84E8T_",
        "outputId": "5eba42d4-5ff3-41e6-90c2-99f0399f9e83"
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.Resize((224,224))])\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.CIFAR10('data', train=True,\n",
        "                              download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10('data', train=False,\n",
        "                             download=True, transform=transform)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)\n",
        "\n",
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90e2453a7f6c44eb8dfe304c649d3659",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GMOO6cgjL67"
      },
      "source": [
        "The Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvU0nZx7GIxI"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(net,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,64,3,padding=1)\n",
        "    self.conv2=nn.Conv2d(64,64,3,padding=1)\n",
        "    #maxpool\n",
        "    self.conv3=nn.Conv2d(64,128,3,padding=1)\n",
        "    self.conv4=nn.Conv2d(128,128,3,padding=1)\n",
        "    #maxpool\n",
        "    self.conv5=nn.Conv2d(128,256,3,padding=1)\n",
        "    self.conv6=nn.Conv2d(256,256,3,padding=1)#*3\n",
        "    #maxpool\n",
        "    self.conv7=nn.Conv2d(256,512,3,padding=1)\n",
        "    self.conv8=nn.Conv2d(512,512,3,padding=1)#*3#maxpool#*4\n",
        "    #maxpool\n",
        "    self.pool=nn.MaxPool2d(2,2)\n",
        "    self.fc1=nn.Linear(7*7*512,4096)\n",
        "    self.fc2=nn.Linear(4096,512)\n",
        "    self.fc3=nn.Linear(512,10)\n",
        "\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=F.relu(self.conv2(x))\n",
        "    x=self.pool(x)\n",
        "    x=F.relu(self.conv3(x))\n",
        "    x=F.relu(self.conv4(x))\n",
        "    x=self.pool(x)\n",
        "    x=F.relu(self.conv5(x))\n",
        "    x=F.relu(self.conv6(x))\n",
        "    x=F.relu(self.conv6(x))\n",
        "    x=F.relu(self.conv6(x))\n",
        "    x=self.pool(x)\n",
        "    x=F.relu(self.conv7(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=self.pool(x)\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=self.pool(x)\n",
        "    x=torch.flatten(x,1)\n",
        "    x=self.dropout(F.relu(self.fc1(x)))\n",
        "    x=self.dropout(F.relu(self.fc2(x)))\n",
        "    x=self.fc3(x)\n",
        "    x=F.softmax(x,dim=1)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZYJNj1O3ld",
        "outputId": "40715ae4-dba9-40b0-9043-38543b18c581"
      },
      "source": [
        "model=net()\n",
        "print(model)\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzsYxHHIPQOD"
      },
      "source": [
        "import torch.optim as optim\n",
        "from  torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min',patience=5)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVmq38nbi_w4"
      },
      "source": [
        "Attempt to train the model at learning rate of 0.001. It did not get completed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4Xo3tEPz_0",
        "outputId": "70abe675-b97e-45e5-9f25-e8db274dc715"
      },
      "source": [
        "epoch=15\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for e in range(epoch):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        #print(loss.item()*data.size(0))\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        e, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 1.842069 \tValidation Loss: 0.460523\n",
            "Validation loss decreased (inf --> 0.460523).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 1.842065 \tValidation Loss: 0.460525\n",
            "Epoch: 2 \tTraining Loss: 1.842064 \tValidation Loss: 0.460527\n",
            "Epoch: 3 \tTraining Loss: 1.842065 \tValidation Loss: 0.460528\n",
            "Epoch: 4 \tTraining Loss: 1.842062 \tValidation Loss: 0.460530\n",
            "Epoch: 5 \tTraining Loss: 1.842059 \tValidation Loss: 0.460532\n",
            "Epoch: 6 \tTraining Loss: 1.842058 \tValidation Loss: 0.460534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZwseth22mgx"
      },
      "source": [
        "import torch.optim as optim\n",
        "from  torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.1,momentum=0.9)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min',patience=5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YlcmagJjgbv"
      },
      "source": [
        "Attempt to train model at lr of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JERJa0IO0_m_",
        "outputId": "a2e20638-b29d-4b09-dc97-53a7c1aa3565"
      },
      "source": [
        "epoch=10\n",
        "valid_loss_min = np.Inf\n",
        "for e in range(1,epoch+1):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        #print(loss.item()*data.size(0))\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        e, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.842208 \tValidation Loss: 0.460548\n",
            "Validation loss decreased (inf --> 0.460548).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 1.842204 \tValidation Loss: 0.460541\n",
            "Validation loss decreased (0.460548 --> 0.460541).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1.842185 \tValidation Loss: 0.460562\n",
            "Epoch: 4 \tTraining Loss: 1.842207 \tValidation Loss: 0.460551\n",
            "Epoch: 5 \tTraining Loss: 1.842188 \tValidation Loss: 0.460560\n",
            "Epoch: 6 \tTraining Loss: 1.842169 \tValidation Loss: 0.460572\n",
            "Epoch: 7 \tTraining Loss: 1.842181 \tValidation Loss: 0.460535\n",
            "Validation loss decreased (0.460541 --> 0.460535).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 1.842107 \tValidation Loss: 0.460538\n",
            "Epoch: 9 \tTraining Loss: 1.842095 \tValidation Loss: 0.460541\n",
            "Epoch: 10 \tTraining Loss: 1.842085 \tValidation Loss: 0.460543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7pFJ6-jQ7I"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t2R-i52YI8d",
        "outputId": "3188265d-0c4a-45b5-d739-1976787d987f"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model,(3,224,224),20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [20, 64, 224, 224]           1,792\n",
            "            Conv2d-2         [20, 64, 224, 224]          36,928\n",
            "         MaxPool2d-3         [20, 64, 112, 112]               0\n",
            "            Conv2d-4        [20, 128, 112, 112]          73,856\n",
            "            Conv2d-5        [20, 128, 112, 112]         147,584\n",
            "         MaxPool2d-6          [20, 128, 56, 56]               0\n",
            "            Conv2d-7          [20, 256, 56, 56]         295,168\n",
            "            Conv2d-8          [20, 256, 56, 56]         590,080\n",
            "            Conv2d-9          [20, 256, 56, 56]         590,080\n",
            "           Conv2d-10          [20, 256, 56, 56]         590,080\n",
            "        MaxPool2d-11          [20, 256, 28, 28]               0\n",
            "           Conv2d-12          [20, 512, 28, 28]       1,180,160\n",
            "           Conv2d-13          [20, 512, 28, 28]       2,359,808\n",
            "           Conv2d-14          [20, 512, 28, 28]       2,359,808\n",
            "           Conv2d-15          [20, 512, 28, 28]       2,359,808\n",
            "        MaxPool2d-16          [20, 512, 14, 14]               0\n",
            "           Conv2d-17          [20, 512, 14, 14]       2,359,808\n",
            "           Conv2d-18          [20, 512, 14, 14]       2,359,808\n",
            "           Conv2d-19          [20, 512, 14, 14]       2,359,808\n",
            "           Conv2d-20          [20, 512, 14, 14]       2,359,808\n",
            "        MaxPool2d-21            [20, 512, 7, 7]               0\n",
            "           Linear-22                 [20, 4096]     102,764,544\n",
            "          Dropout-23                 [20, 4096]               0\n",
            "           Linear-24                  [20, 512]       2,097,664\n",
            "          Dropout-25                  [20, 512]               0\n",
            "           Linear-26                   [20, 10]           5,130\n",
            "================================================================\n",
            "Total params: 124,891,722\n",
            "Trainable params: 124,891,722\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 11.48\n",
            "Forward/backward pass size (MB): 2501.17\n",
            "Params size (MB): 476.42\n",
            "Estimated Total Size (MB): 2989.08\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkKuP5SwXekR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffa68da-15bf-4647-e54d-adf8cf6c5032"
      },
      "source": [
        "model.load_state_dict(torch.load('model_cifar.pt'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}